# Scaling & Mitigation Strategies - Detailed Implementation Guide

**Last Updated:** October 28, 2025  
**Focus:** Vertical scaling with Railway (CPU/RAM upgrades)  
**Budget:** Willing to invest in infrastructure for optimal performance

---

## Executive Summary

Your current bottleneck is **replay parsing workers** (2 workers processing at 75% capacity). Good news: **This is the easiest bottleneck to solve** - just add more workers and RAM.

**The best mitigation strategy is simple vertical scaling:**
- Increase worker pool size: 2 â†’ 4 â†’ 8
- Upgrade Railway plan for more RAM/CPU
- Zero code changes required
- 5-minute implementation time

**Cost to double capacity: ~$10-20/month**  
**Cost to 4Ã— capacity: ~$30-40/month**

This document provides detailed implementation steps and cost analysis.

---

## Current Capacity & Bottlenecks

### Current Setup
- **Workers:** 2 processes
- **Memory:** ~380 MB used
- **CPU:** ~1.5 cores utilized
- **Capacity:** 200 concurrent users (75% of replay bottleneck)

### Bottleneck Analysis

| Bottleneck | Current Capacity | Utilization at 200 Users | Headroom |
|------------|-----------------|--------------------------|----------|
| **1. Replay Parsing** | 4 replays/sec | 75% | **Primary constraint** |
| 2. Discord API | 50 calls/sec | 13% | 5Ã— headroom |
| 3. Database Writes | 75 writes/sec | 9% | 10Ã— headroom |
| 4. Memory | 512-1024 MB | 40-75% | 2Ã— headroom |
| 5. CPU | 2-4 cores | 37-75% | 2Ã— headroom |

**Replay parsing is your only real bottleneck.** Everything else has massive headroom.

---

## Mitigation Strategy Tiers

### ðŸ¥‰ **Tier 1: Free (Monitoring Only)**
**Cost:** $0  
**Capacity gain:** 0%  
**Implementation time:** 2-4 hours

#### Actions:
1. Implement `load_monitor.py` service
2. Add replay queue depth logging
3. Set up alerts for threshold breaches
4. Monitor actual usage patterns in production

#### Benefits:
- Know when you're approaching limits
- Get advance warning before hitting bottleneck
- Data-driven scaling decisions

#### When to do this:
- **Immediately, before launch**
- Essential for all other strategies

---

### ðŸ¥ˆ **Tier 2: Simple Worker Scaling (Vertical)**
**Cost:** $10-20/month additional  
**Capacity gain:** 100-300%  
**Implementation time:** 5 minutes

#### Option 2A: Double Workers (2 â†’ 4)
**New capacity:** 400-480 concurrent users  
**Railway plan:** Hobby â†’ Pro ($5 â†’ $20/month)

```env
# In Railway environment variables
WORKER_PROCESSES=4
```

**Resource requirements:**
- RAM: 580 MB (380 base + 100 MB Ã— 2 workers)
- CPU: 2-2.5 cores
- Railway plan: **Pro ($20/month)**

**Capacity increase:**
- Replay parsing: 4 â†’ 8 replays/second (+100%)
- Max concurrent: 240 â†’ 480 users (+100%)
- Weekly active: 1,900 â†’ 3,800 users (+100%)

#### Option 2B: Quadruple Workers (2 â†’ 8)
**New capacity:** 800-960 concurrent users  
**Railway plan:** Pro with higher limits ($20-30/month)

```env
WORKER_PROCESSES=8
```

**Resource requirements:**
- RAM: 980 MB (380 base + 100 MB Ã— 6 additional workers)
- CPU: 3-4 cores
- Railway plan: **Pro with resource scaling ($30/month)**

**Capacity increase:**
- Replay parsing: 4 â†’ 16 replays/second (+300%)
- Max concurrent: 240 â†’ 960 users (+300%)
- Weekly active: 1,900 â†’ 7,600 users (+300%)

#### Implementation Steps:

1. **Update environment variable in Railway:**
   ```
   Dashboard â†’ Your Service â†’ Variables â†’ WORKER_PROCESSES â†’ 4
   ```

2. **Verify Railway plan has sufficient resources:**
   - Pro plan: 8GB RAM, 8 vCPU (more than enough)
   - Resources allocated per service, not shared

3. **Deploy (automatic with env var change)**
   - Railway auto-redeploys on env change
   - ~2-3 minute deployment time

4. **Verify workers started:**
   - Check logs: `[ProcessPool] Initialized with 4 workers`
   - Monitor queue depth: Should stay at 0-2 even under load

#### Cost-Benefit Analysis:

| Workers | Railway Plan | Cost/Month | Max Concurrent | Cost per 100 Users |
|---------|-------------|------------|----------------|-------------------|
| 2 | Hobby | $5 | 240 | $2.08 |
| 4 | Pro | $20 | 480 | $4.17 |
| 8 | Pro | $30 | 960 | $3.13 |

**Best value: 4 workers at $20/month**

---

### ðŸ¥‡ **Tier 3: Aggressive Vertical Scaling**
**Cost:** $30-50/month  
**Capacity gain:** 300-500%  
**Implementation time:** 10-15 minutes

#### Recommended Configuration:
```env
# Railway environment variables
WORKER_PROCESSES=8
DB_POOL_MAX_CONNECTIONS=50
DB_POOL_MIN_CONNECTIONS=10
```

**Railway plan:** Pro ($20/month base + usage-based scaling)

#### Resource Allocation:
- **RAM:** 2 GB (comfortable headroom)
- **CPU:** 4 cores (handle burst traffic)
- **Database connections:** 50 max pool

#### Additional Optimizations:

##### 1. Increase Database Connection Pool
**Current:** 10 min, 20 max  
**Recommended:** 10 min, 50 max

```python
# In src/bot/config.py
DB_POOL_MIN_CONNECTIONS = int(os.getenv("DB_POOL_MIN_CONNECTIONS", "10"))
DB_POOL_MAX_CONNECTIONS = int(os.getenv("DB_POOL_MAX_CONNECTIONS", "50"))
```

**Benefit:** Prevents connection exhaustion during write bursts  
**Cost impact:** Supabase Pro can handle 200+ connections

##### 2. Tune Matchmaking Interval (Optional)
**Current:** 45 seconds  
**Option:** Reduce to 30 seconds for faster matching

```env
MM_MATCH_INTERVAL_SECONDS=30
```

**Trade-off:** 
- Faster matching (better UX)
- More frequent matchmaking runs (+50% CPU during waves)
- Still well within capacity

##### 3. Process Pool Health Monitoring
Already built into your system, just enable logging:

```python
# In bot_setup.py, add health check task
async def start_background_tasks(self):
    # Existing tasks...
    
    # Add process pool health monitoring
    self._process_pool_monitor_task = asyncio.create_task(
        self._monitor_process_pool_health()
    )
```

#### Expected Performance:
- **Max concurrent:** 800-960 users
- **Weekly active:** 6,400-7,600 users
- **Replay queue:** Stays at 0-2 even during bursts
- **Match completion:** <2 seconds consistently
- **System utilization:** 40-50% (excellent headroom)

---

## Railway-Specific Optimization

### Railway Plans Comparison

| Plan | Price | RAM | vCPU | Execution Time | Best For |
|------|-------|-----|------|---------------|----------|
| **Hobby** | $5/mo | 512 MB | 1 vCPU | 500 hrs/mo | Alpha testing (<150 users) |
| **Pro** | $20/mo | 8 GB | 8 vCPU | Unlimited | Production (150-1000 users) |
| **Team** | Custom | Custom | Custom | Unlimited | Enterprise (>1000 users) |

**Recommendation: Pro plan ($20/month)**
- 8 GB RAM (20Ã— what you need)
- 8 vCPU (perfect for 8 workers + main process)
- Unlimited execution time
- Metrics dashboard
- Automatic scaling within limits

### Railway Resource Allocation Strategy

#### Configuration A: Balanced (Recommended)
**Cost:** $20/month (Pro plan)

```yaml
# railway.json
{
  "deploy": {
    "numReplicas": 1,
    "healthcheckPath": "/health",
    "restartPolicyType": "ON_FAILURE"
  }
}
```

**Service resources:**
- 4 worker processes
- 2 GB RAM allocated (rest reserved)
- 4 vCPU allocated
- **Capacity:** 480 concurrent users

#### Configuration B: High-Performance
**Cost:** $30-40/month (Pro plan with higher resource usage)

```yaml
{
  "deploy": {
    "numReplicas": 1,
    "healthcheckPath": "/health",
    "restartPolicyType": "ON_FAILURE"
  }
}
```

**Service resources:**
- 8 worker processes
- 4 GB RAM allocated
- 6 vCPU allocated
- **Capacity:** 960 concurrent users

#### Configuration C: Redundant (High Availability)
**Cost:** $60-80/month (2Ã— Pro instances + load balancer)

This is **NOT recommended yet** - premature optimization.  
Wait until you actually need >960 concurrent.

---

## Worker Scaling Math & Cost Analysis

### Worker Count vs. Capacity

| Workers | Replay Capacity | Max Concurrent | WAU (5hr/week) | Railway Cost | Cost/100 Users |
|---------|----------------|----------------|----------------|--------------|----------------|
| 2 | 4/sec | 240 | 1,900 | $5-10 | $2.08-4.17 |
| 4 | 8/sec | 480 | 3,800 | $20 | $4.17 |
| 6 | 12/sec | 720 | 5,700 | $25 | $3.47 |
| 8 | 16/sec | 960 | 7,600 | $30 | $3.13 |
| 12 | 24/sec | 1,440 | 11,400 | $40 | $2.78 |
| 16 | 32/sec | 1,920 | 15,200 | $50 | $2.60 |

### Cost per Worker

**Each worker adds:**
- ~100 MB RAM
- ~0.5 CPU (during active parsing)
- ~$2-5/month Railway cost

**Diminishing returns after 8 workers** - other bottlenecks emerge.

### Sweet Spot Analysis

**Best Value: 4 Workers**
- Cost: $20/month
- Capacity: 480 concurrent (3,800 WAU)
- Cost per user: $0.042/month (4.2 cents)
- Headroom: 2Ã— current target

**Best Performance: 8 Workers**
- Cost: $30/month  
- Capacity: 960 concurrent (7,600 WAU)
- Cost per user: $0.031/month (3.1 cents)
- Headroom: 4Ã— current target

**Recommendation: Start with 4, scale to 8 if needed**

---

## Memory Optimization (If Needed)

### Current Memory Breakdown
- In-memory DataFrames: 130 MB (at 1,500 players)
- Process pool workers: 100 MB (2 workers)
- Bot process: 100 MB
- OS overhead: 50 MB
- **Total: ~380 MB**

### Memory Scaling by Player Count

| Players | DataFrame Size | Total Memory (2 workers) | Total (4 workers) | Total (8 workers) |
|---------|---------------|-------------------------|-------------------|-------------------|
| 500 | 45 MB | 195 MB | 295 MB | 495 MB |
| 1,500 | 130 MB | 280 MB | 480 MB | 880 MB |
| 5,000 | 430 MB | 580 MB | 780 MB | 1,180 MB |
| 10,000 | 860 MB | 1,010 MB | 1,210 MB | 1,610 MB |
| 20,000 | 1,720 MB | 1,870 MB | 2,070 MB | 2,470 MB |

### Memory Mitigation Options

#### Option 1: Polars DataFrame Optimization (Free)
Current DataFrames are already optimized, but you can reduce history:

```python
# In data_access_service.py
# Reduce match history in memory
matches_data = await loop.run_in_executor(
    None,
    self._db_reader.adapter.execute_query,
    "SELECT * FROM matches_1v1 ORDER BY played_at DESC LIMIT 10000",  # Instead of all
    {}
)
```

**Savings:** ~50-70% of match DataFrame size  
**Trade-off:** Older matches need DB query (rare)

#### Option 2: Lazy DataFrame Loading (Free)
Don't load replay metadata into memory:

```python
# In _load_all_tables()
# Skip replay DataFrame (query DB when needed)
self._replays_df = None  # Don't load
```

**Savings:** 90 MB (replay DataFrame)  
**Trade-off:** Replay lookups require DB query (infrequent)

#### Option 3: Just Buy More RAM (Recommended)
**Cost:** $0 (included in Pro plan)  
**Railway Pro:** 8 GB RAM  
**Your usage at 20,000 players:** 2.5 GB

**You won't run out of RAM until ~50,000 players**

---

## CPU Optimization

### Current CPU Usage
- Main bot process: 10-20% of 1 core
- Background writer: 10% of 1 core  
- Matchmaking waves: Burst to 50% every 45 seconds
- Worker processes: 15% average (2 workers)

**Total: 1.5 cores sustained, 2-2.5 cores peak**

### CPU Scaling by Workers

| Workers | Sustained CPU | Peak CPU | Recommended vCPU |
|---------|--------------|----------|------------------|
| 2 | 1.5 cores | 2.5 cores | 2 vCPU |
| 4 | 2.5 cores | 4 cores | 4 vCPU |
| 8 | 4 cores | 6 cores | 6 vCPU |
| 12 | 5.5 cores | 8 cores | 8 vCPU |

**Railway Pro provides 8 vCPU** - more than enough for 8-12 workers.

### CPU Mitigation Options

#### Option 1: Reduce Matchmaking Frequency (Not Recommended)
Increase `MM_MATCH_INTERVAL_SECONDS` from 45 to 60.

**Savings:** 25% reduction in matchmaking CPU  
**Trade-off:** Players wait 33% longer for matches (bad UX)

**Verdict:** Don't do this. CPU is cheap, user patience is not.

#### Option 2: Optimize Rank Calculations (Already Done)
Your system already caches rank calculations in `RankingService`.

```python
# This is already implemented
ranking_service.get_letter_rank(player_id, race)  # Cached, <0.1ms
```

**Status:** âœ… Already optimized

#### Option 3: Offload Replay Parsing to Separate Service (Overkill)
Create dedicated replay parsing microservice.

**Benefit:** Isolates CPU-intensive work  
**Cost:** +$20/month (separate Railway service)  
**Complexity:** High (service-to-service communication)

**Verdict:** Unnecessary until 1,000+ concurrent users

---

## Database Scaling (Supabase)

### Current Supabase Usage
- **Reads:** 0/sec (all in-memory)
- **Writes:** 6.7/sec sustained
- **Storage:** ~50 KB per player + 400 KB per replay
- **Connections:** 10-20 concurrent

### Supabase Plan Comparison

| Plan | Price | Storage | Bandwidth | DB Size | Connections |
|------|-------|---------|-----------|---------|-------------|
| **Free** | $0 | 500 MB | 2 GB | 500 MB | 60 |
| **Pro** | $25/mo | 8 GB | 50 GB | 100 GB | 200 |
| **Team** | $599/mo | 100 GB | 250 GB | 200 GB | 400 |

**Current recommendation: Pro ($25/month)**
- 8 GB storage (enough for 20,000 replays)
- 50 GB bandwidth
- 200 connections (way more than needed)

### When to Upgrade Supabase

**Stay on Free if:**
- <500 players
- <1,000 replays
- Alpha/early beta testing

**Upgrade to Pro at:**
- 500-1,000 players
- 1,000+ replays
- Launching to public beta

**You'll never need Team plan** - Pro handles 10,000+ concurrent connections.

### Database Optimization Options

#### Option 1: Connection Pooling (Already Implemented)
Your `connection_pool.py` already does this.

```python
# In connection_pool.py
pool = await asyncpg.create_pool(
    DATABASE_URL,
    min_size=DB_POOL_MIN_CONNECTIONS,
    max_size=DB_POOL_MAX_CONNECTIONS
)
```

**Status:** âœ… Already optimized

#### Option 2: Write Batching (Already Implemented)
Your `DataAccessService` write queue batches operations.

**Status:** âœ… Already optimized

#### Option 3: Add Read Replicas (Unnecessary)
Since you have 0 database reads, replicas provide zero benefit.

**Verdict:** Don't do this. Your architecture doesn't need it.

---

## Discord API Scaling

### Current Discord API Usage
- **Sustained:** 6.75 calls/second
- **Peak:** 11.25 calls/second
- **Discord Limit:** 50 calls/second

**You're at 13-22% of Discord's limit.**

### Discord API Mitigation Options

#### Option 1: Request Rate Limiting (If Approaching Limit)
Add rate limiter to prevent bursts:

```python
# In discord_utils.py
import asyncio
from collections import deque

class RateLimiter:
    def __init__(self, max_calls: int, time_window: float):
        self.max_calls = max_calls
        self.time_window = time_window
        self.calls = deque()
    
    async def acquire(self):
        now = time.time()
        
        # Remove old calls outside time window
        while self.calls and self.calls[0] < now - self.time_window:
            self.calls.popleft()
        
        # Wait if at limit
        if len(self.calls) >= self.max_calls:
            sleep_time = self.calls[0] + self.time_window - now
            await asyncio.sleep(sleep_time)
            return await self.acquire()
        
        self.calls.append(now)

# Global rate limiter (40/sec = 80% of Discord limit)
discord_rate_limiter = RateLimiter(max_calls=40, time_window=1.0)

async def rate_limited_api_call(func, *args, **kwargs):
    await discord_rate_limiter.acquire()
    return await func(*args, **kwargs)
```

**When to implement:** Only if you consistently hit 40+ calls/second

**Current verdict:** Not needed (you're at 6.75/sec)

#### Option 2: Batch Embed Updates (Minor Gains)
Instead of sending individual updates, batch them:

```python
# Instead of:
await channel.send(embed1)
await channel.send(embed2)

# Do:
await asyncio.gather(
    channel.send(embed1),
    channel.send(embed2)
)
```

**Savings:** Reduces latency, same API call count  
**Complexity:** Low  
**Recommendation:** Nice to have, not critical

#### Option 3: Reduce Leaderboard Page Size (Not Recommended)
Show fewer entries per page to reduce render time.

**Trade-off:** More page clicks (worse UX)  
**Verdict:** Don't do this. Current system is fine.

---

## Long-Term Horizontal Scaling (>1,000 Concurrent)

### When Vertical Scaling Maxes Out

**Vertical scaling limits hit at:**
- ~16-20 worker processes
- ~1,920-2,400 concurrent users
- ~15,000-19,000 weekly active users
- $50-60/month Railway cost

**At that point, you need horizontal scaling.**

### Horizontal Scaling Architecture

#### Phase 1: Redis Cache Migration
**Replace in-memory DataFrames with Redis**

**Benefits:**
- Multiple bot instances share cache
- 2-4Ã— throughput increase
- Supports 3,000-5,000 concurrent

**Costs:**
- Redis: $10-30/month (Railway Redis addon)
- Development: 2-3 weeks
- Slightly higher latency (0.5-2ms vs <0.1ms)

**Implementation:**
```python
# New redis_data_service.py
class RedisDataAccessService:
    def __init__(self):
        self.redis = redis.Redis(connection_pool=pool)
    
    async def get_player_info(self, discord_uid: int) -> dict:
        # 0.5-2ms instead of <0.1ms
        data = await self.redis.hgetall(f"player:{discord_uid}")
        return json.loads(data) if data else None
```

#### Phase 2: Separate Replay Parsing Service
**Dedicated microservice for CPU-intensive parsing**

**Benefits:**
- Isolates bottleneck
- Independent scaling
- Better resource utilization

**Costs:**
- +$20/month (separate Railway service)
- Development: 1-2 weeks
- Service-to-service communication overhead

**Architecture:**
```
Discord Bot (Main) â”€â”€REST APIâ”€â”€> Replay Parser Service
       â”‚                              â”‚
       â””â”€â”€â”€â”€ Redis Cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Phase 3: Multiple Bot Instances (Load Balancing)
**Run 2-4 bot instances behind Discord's sharding**

**Benefits:**
- Discord handles load distribution
- Natural fault tolerance
- Linear scaling

**Costs:**
- +$20-40/month per instance
- Redis required (shared state)
- Shard coordination logic

**When to implement:** >5,000 concurrent users

---

## Recommended Scaling Timeline

### Phase 1: Alpha Launch (Now)
**Target:** 100-200 concurrent users

**Configuration:**
- 2 workers
- Railway Hobby ($5/month)
- Supabase Free
- **Total: $5/month**

**Actions:**
1. Deploy current codebase
2. Implement monitoring
3. Collect real usage data

---

### Phase 2: Beta Launch (Month 2-3)
**Target:** 200-400 concurrent users

**Configuration:**
- 4 workers
- Railway Pro ($20/month)
- Supabase Pro ($25/month)
- **Total: $45/month**

**Actions:**
1. Upgrade to 4 workers (5-minute config change)
2. Upgrade Supabase to Pro
3. Monitor queue depths

**Trigger:** When replay queue consistently >5

---

### Phase 3: Public Launch (Month 4-6)
**Target:** 400-800 concurrent users

**Configuration:**
- 8 workers
- Railway Pro ($30/month with higher usage)
- Supabase Pro ($25/month)
- **Total: $55/month**

**Actions:**
1. Increase to 8 workers
2. Optimize based on beta feedback
3. Add advanced monitoring

**Trigger:** When peak concurrent >350 regularly

---

### Phase 4: Growth (Month 6-12)
**Target:** 800-1,500 concurrent users

**Configuration:**
- 12-16 workers
- Railway Pro ($40-50/month)
- Supabase Pro ($25/month)
- **Total: $65-75/month**

**Actions:**
1. Increase workers to 12-16
2. Consider Redis migration prep
3. Evaluate horizontal scaling need

**Trigger:** When peak concurrent >700

---

### Phase 5: Scale (Month 12+)
**Target:** 1,500+ concurrent users

**Configuration:**
- Redis + multiple instances
- Railway Pro Ã— 2-3 ($60-80/month)
- Supabase Pro ($25/month)
- Redis ($20/month)
- **Total: $105-125/month**

**Actions:**
1. Migrate to Redis cache
2. Deploy multiple bot instances
3. Separate replay parsing service

**Trigger:** When vertical scaling maxes out (>1,500 concurrent)

---

## Implementation Checklist

### Immediate (Pre-Launch)
- [ ] Implement load monitoring (`load_monitor.py`)
- [ ] Add replay queue depth alerts
- [ ] Document worker scaling procedure
- [ ] Test 4-worker configuration locally
- [ ] Verify Railway Pro plan features

### Short-Term (Month 1-2)
- [ ] Collect production metrics
- [ ] Identify actual usage patterns
- [ ] Set alert thresholds based on real data
- [ ] Prepare worker scaling runbook

### Medium-Term (Month 2-6)
- [ ] Scale workers as needed (4 â†’ 8)
- [ ] Optimize based on bottlenecks observed
- [ ] Evaluate cost vs. performance
- [ ] Plan Redis migration if approaching limits

### Long-Term (Month 6-12)
- [ ] Begin Redis migration if >800 concurrent
- [ ] Evaluate horizontal scaling architecture
- [ ] Consider dedicated replay service
- [ ] Optimize for cost efficiency at scale

---

## Cost Projection Model

### Revenue Model (assuming $3/month subscription)

| Concurrent | WAU (5hr/wk) | Revenue/mo | Infrastructure | Profit | Margin |
|-----------|--------------|------------|----------------|--------|--------|
| 100 | 800 | $2,400 | $5 | $2,395 | 99.8% |
| 200 | 1,600 | $4,800 | $45 | $4,755 | 99.1% |
| 400 | 3,200 | $9,600 | $45 | $9,555 | 99.5% |
| 800 | 6,400 | $19,200 | $55 | $19,145 | 99.7% |
| 1,500 | 12,000 | $36,000 | $75 | $35,925 | 99.8% |
| 3,000 | 24,000 | $72,000 | $125 | $71,875 | 99.8% |

**Key insight: Infrastructure cost is negligible compared to revenue.**

Even at 3,000 concurrent users (24,000 WAU), infrastructure is only **0.17%** of revenue.

**You can afford to throw money at Railway without worrying.**

---

## Emergency Scaling Procedures

### If Replay Queue Suddenly Spikes

**Symptoms:**
- Queue depth >20
- Player complaints about slow verification
- Match completion time >5 seconds

**Immediate action (5 minutes):**
1. Go to Railway dashboard
2. Variables â†’ `WORKER_PROCESSES` â†’ Change to `8`
3. Save (auto-redeploys)
4. Monitor queue depth for 10 minutes
5. Should drop to <5 within 5 minutes

**If still overloaded:**
1. Change to `WORKER_PROCESSES=12`
2. Verify Railway Pro plan has resources
3. Monitor memory usage

### If Memory Exhaustion

**Symptoms:**
- Bot crashes with OOM error
- Slow response times
- Railway dashboard shows 90%+ memory

**Immediate action (10 minutes):**
1. Reduce match history in memory:
   ```python
   # In data_access_service.py
   LIMIT 5000  # Instead of all matches
   ```
2. Disable replay DataFrame loading
3. Redeploy

**Long-term fix:**
- Upgrade to Railway Team plan (if needed)
- Implement DataFrame pruning
- Consider Redis migration

### If Database Connection Exhaustion

**Symptoms:**
- Errors: "too many connections"
- Writes failing
- Queue backing up

**Immediate action (5 minutes):**
1. Increase connection pool:
   ```env
   DB_POOL_MAX_CONNECTIONS=50
   ```
2. Upgrade Supabase to Pro (if on Free)
3. Monitor connection count

---

## Monitoring & Alerting Setup

### Critical Metrics to Track

1. **Replay Queue Depth**
   - Alert: >10 (warning)
   - Critical: >20 (immediate action)

2. **Database Write Queue**
   - Alert: >100 (warning)
   - Critical: >500 (immediate action)

3. **Memory Usage**
   - Alert: >70%
   - Critical: >85%

4. **Match Completion Time**
   - Alert: >3 seconds average
   - Critical: >5 seconds

5. **Discord API Rate**
   - Alert: >35 calls/second (approaching limit)
   - Critical: >45 calls/second

### Alerting Channels

**Option 1: Discord Webhook (Recommended)**
```python
# Send alerts to admin channel
async def send_alert(level: str, message: str):
    webhook_url = os.getenv("ADMIN_WEBHOOK_URL")
    async with aiohttp.ClientSession() as session:
        await session.post(webhook_url, json={
            "content": f"ðŸš¨ **{level}**: {message}"
        })
```

**Option 2: Railway Built-In Alerts**
- Set up in Railway dashboard
- Email notifications
- Slack integration available

**Option 3: External Monitoring (Overkill)**
- Datadog, New Relic, etc.
- $50-100/month
- Only needed for >10,000 users

---

## Final Recommendations

### Best Vertical Scaling Strategy

**Start conservative:**
1. Launch with 2 workers on Hobby ($5/month)
2. Collect 1-2 weeks of real data
3. Upgrade to Pro + 4 workers when hitting 150+ concurrent ($45/month)
4. Scale to 8 workers when hitting 350+ concurrent ($55/month)

**Each scaling decision:**
- Takes 5 minutes to implement
- Doubles capacity
- Costs $10-20/month more

**You'll never regret buying more Railway resources** - they're cheap compared to losing users to slow performance.

### Budget Allocation

**For first 6 months:**
- Infrastructure: $300-400 total
- Development time: ~40 hours
- Support tools: $50-100

**Total: ~$500** to reach 1,000+ concurrent users

**Cost per user acquired: ~$0.05**

### When to Move to Horizontal Scaling

**Don't rush into horizontal scaling:**
- Vertical scales to 1,500-2,000 concurrent
- Redis adds complexity
- Only needed after Month 6-12

**Trigger points:**
- Sustained >1,200 concurrent users
- Worker count >16
- Railway costs >$80/month

**Until then, just throw more RAM/CPU at Railway.**

---

## Conclusion

**Your mitigation strategy is simple:**

1. **Implement monitoring** (free, 2-4 hours)
2. **Scale workers as needed** ($10-20/month, 5 minutes)
3. **Don't worry about costs** (infrastructure is <1% of revenue)

**The cost to 4Ã— your capacity is $30/month.**

At $3/month per user, you break even at just 10 users. Everything else is profit.

**Recommendation: Start with 2 workers, scale to 4 when you hit 150 concurrent users, then to 8 at 350.**

Railway makes this trivially easy. Your architecture is designed perfectly for vertical scaling.

**Just throw money at Railway and focus on growing your user base.** The infrastructure will scale effortlessly.

---

**Total estimated cost to serve 1,000 concurrent users: $55/month**  
**Revenue from 8,000 WAU at $3/month: $24,000/month**  
**Margin: 99.77%**

**Infrastructure is not your constraint. User acquisition is.**

